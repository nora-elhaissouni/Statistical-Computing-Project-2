---
title: "HW 4 Q5"
output: html_document
date: "2023-10-16"
---

```{r}
set.seed(567)
num_simulations <- 100000
# Mid Point for the small and group size suggestion
sample_size_small <- 15
sample_size_large <- 450

#I am comparing everything against the null, which is why I use 


#Small sample size sims first
#Normal distribution Small SS
p_values_small_normal <- replicate(num_simulations, {
  group1 <- rnorm(sample_size_small)
  group2 <- rnorm(sample_size_small)
  p_value <- t.test(group1, group2)$p.value
  return(p_value)
})
proportion_small_normal <- mean(p_values_small_normal <= 0.05)

#t-distr Small SS
p_values_small_t <- replicate(num_simulations, {
  group1 <- rnorm(sample_size_small)
  group2 <- rt(sample_size_small, df = 3)
  p_value <- t.test(group1, group2)$p.value
  return(p_value)
})
proportion_small_t <- mean(p_values_small_t <= 0.05)

#Chi sq distr Small SS
p_values_small_chi2 <- replicate(num_simulations, {
  group1 <- rnorm(sample_size_small)
  group2 <- rchisq(sample_size_small, df = 1)
  p_value <- t.test(group1, group2)$p.value
  return(p_value)
})
proportion_small_chi2 <- mean(p_values_small_chi2 <= 0.05)

#Here I start for the large Sample size
#Normal distribution LSS
p_values_large_normal <- replicate(num_simulations, {
  group1 <- rnorm(sample_size_large)
  group2 <- rnorm(sample_size_large)
  p_value <- t.test(group1, group2)$p.value
  return(p_value)
})
proportion_large_normal <- mean(p_values_large_normal <= 0.05)

#t-dist LSS
p_values_large_t <- replicate(num_simulations, {
  group1 <- rnorm(sample_size_large)
  group2 <- rt(sample_size_large, df = 3)
  p_value <- t.test(group1, group2)$p.value
  return(p_value)
})
proportion_large_t <- mean(p_values_large_t <= 0.05)

#Chi-sq distr LSS
p_values_large_chi2 <- replicate(num_simulations, {
  group1 <- rnorm(sample_size_large)
  group2 <- rchisq(sample_size_large, df = 1)
  p_value <- t.test(group1, group2)$p.value
  return(p_value)
})
proportion_large_chi2 <- mean(p_values_large_chi2 <= 0.05)

# Create a tibble to store the results
results_tibble <- tibble(
  Scenario = c("Normal (Small)", "t-distribution (Small)", "chi-squared distribution (Small)",
               "Normal (Large)", "t-distribution (Large)", "chi-squared distribution (Large)"),
  Proportion_P_0.05 = c(proportion_small_normal, proportion_small_t, proportion_small_chi2,
                        proportion_large_normal, proportion_large_t, proportion_large_chi2)
)

# Display the results tibble
print(results_tibble)



# Interpret the results:
# We know that a well-behaved error rate is the common alpha, which we also learned is the probability of type 1 error. Thus from the findings we can look at the proportion of p-values--from the tests I ran--less than 0.05 in the hopes that they are close to 0.05. In class we talked about how the T-test was created to use sample standard deviations or for a small sample size instead of the normal distribution. Thus, it is expected that when comparing two groups, ones with normal and t distributed random variables, we see that the proportion of the values for rejection of the null is close to 0.05 (the alpha level/type 1 error probability). Since T distributed data converges to normal with an increased sample size, we see that for the larger sample where we compared the t-distribution to the normal as a reference, the value is even closer to 0.05 then when we used the small sample size. Thus, the t-test is robust for both small and large samples, but more so for large. For chi-squared, the proportion of p values less than 0.05 is 0.62 for small sample sizes and 1 for large sample sizes. This indicates that the tests between chi-squared and normal RV's is not correctly rejecting the null hypothesis when it should (type 2 error). The chisquare and normal two sample t test is not robust.For comparing sets of Normal RV's in a t-test we see that it is pretty robust for both small and large sample sizes.

```

